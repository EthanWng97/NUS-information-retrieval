{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM24OwBgMOiJTKAvIlEF8pJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NavePnow/CS3245-Information-Retrieval-NUS/blob/master/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOKff-qG6nZY",
        "colab_type": "code",
        "outputId": "64193f51-3cd9-44e1-974a-5f134d1b08cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0qBBNJl3ocz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_LM(in_file):\n",
        "    \"\"\"\n",
        "    build language models for each label\n",
        "    each line in in_file contains a label and a string separated by a space\n",
        "    \"\"\"\n",
        "    print('building language models...')\n",
        "    start = time.time()\n",
        "    # Language model\n",
        "    dict_lm = {} \n",
        "    input_file = open(in_file, 'r')\n",
        "    for line in input_file:\n",
        "        [label, text] = line.split(' ', 1)\n",
        "        # Generate 4-gram phrase\n",
        "        strings = []\n",
        "        # Q1: delete Period at end of the sentence?\n",
        "        for i in range(len(text)-WINDOW_SIZE):\n",
        "            strings.append(text[i: i + WINDOW_SIZE])\n",
        "        # Count the phrase and feed them into language model\n",
        "        for string in strings:\n",
        "            if string not in dict_lm:\n",
        "                # Initialize the language model\n",
        "                dict_lm[string] = {}\n",
        "                for tmp_label in dict_label:  \n",
        "                    dict_lm[string][tmp_label] = 0\n",
        "                dict_lm[string][label] = 1\n",
        "            else:\n",
        "                dict_lm[string][label] += 1\n",
        "    input_file.close()\n",
        "    # Calculate the total word count of each language\n",
        "    for key, value in dict_lm.items():\n",
        "        for key_l in dict_label:\n",
        "            dict_label[key_l] += dict_lm[key][key_l]\n",
        "    add_one = len(dict_lm)  # add-one smoothing\n",
        "    dict_lm_pro = copy.deepcopy(dict_lm) # Use probability instead of count\n",
        "    for key, value in dict_lm_pro.items():\n",
        "        for key_l in dict_label:\n",
        "            dict_lm_pro[key][key_l] = (dict_lm[key][key_l] + 1)/(add_one + dict_label[key_l]) # Formula told on lecture\n",
        "    end = time.time()\n",
        "    print('build language models successfully')\n",
        "    print('execution time: '+ str(end-start)+ 's')\n",
        "    return (dict_lm_pro)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr_DRXSLcBGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_LM(in_file, out_file, LM):\n",
        "    \"\"\"\n",
        "    test the language models on new strings\n",
        "    each line of in_file contains a string\n",
        "    you should print the most probable label for each string into out_file\n",
        "    \"\"\"\n",
        "    print(\"testing language models...\")\n",
        "    input_file = open(in_file, 'r')\n",
        "    output_file = open(out_file, 'w')\n",
        "    # threshold of extraterrestrial aliens\n",
        "    threshold = 0.5\n",
        "    for line in input_file:\n",
        "        label_pro = {'malaysian': 0, 'indonesian': 0, 'tamil': 0}\n",
        "        [label, text] = line.split(' ', 1)\n",
        "        strings = []\n",
        "        miss_count = 0\n",
        "        # Generate 4-gram phrase\n",
        "        for i in range(len(text)-WINDOW_SIZE):\n",
        "            strings.append(text[i: i + WINDOW_SIZE])\n",
        "        # Calculate the probability\n",
        "        for string in strings:\n",
        "            # Ignore if phrase got absent\n",
        "            if string not in LM:\n",
        "                miss_count += 1\n",
        "                continue\n",
        "            # Use log instead of multiply\n",
        "            for key in dict_label:\n",
        "                label_pro[key] += math.log(LM[string][key])\n",
        "        miss_pro = miss_count / len(strings)\n",
        "        if miss_pro > threshold:\n",
        "            result = \"other\"\n",
        "        else:\n",
        "            # Select the maximum of three languages\n",
        "            result = sorted(\n",
        "                label_pro.items(), key=lambda label_pro: label_pro[1], reverse=True)[0][0]\n",
        "        output_file.write(result + \" \" + line)\n",
        "    input_file.close()\n",
        "    output_file.close()\n",
        "    print('test language models successfully')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dx9QyKPk7rdC",
        "colab_type": "code",
        "outputId": "a2d12ef3-7258-43c9-fa93-efbd1a047e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "import re\n",
        "import nltk\n",
        "import sys\n",
        "import getopt\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "WINDOW_SIZE = 4\n",
        "dict_label = {'malaysian': 0, 'indonesian': 0, 'tamil': 0}\n",
        "# LM = build_LM(input_file_b)\n",
        "# test_LM(input_file_t, output_file, LM)\n",
        "\n",
        "LM = build_LM('/content/drive/My Drive/input.train.txt')\n",
        "# test_LM(input_file_t, output_file, LM)\n",
        "test_LM('/content/drive/My Drive/input.test.txt', '/content/drive/My Drive/input.predict.txt', LM)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "building language models...\n",
            "build language models successfully\n",
            "execution time: 0.25275754928588867s\n",
            "testing language models...\n",
            "test language models successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vu-QVNR4shW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "64dc00ed-30d4-4817-d38d-ed45e3a4e1d0"
      },
      "source": [
        "!python3 /content/drive/My\\ Drive/eval.py /content/drive/My\\ Drive/input.predict.txt /content/drive/My\\ Drive/input.correct.txt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 20 / 20 (100.0%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryt7o0BYHFuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "outputId": "c0b3baa4-b454-4bed-871b-460149ce1205"
      },
      "source": [
        "!python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9 (default, Nov  7 2019, 10:44:02) \n",
            "[GCC 8.3.0] on linux\n",
            "Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n",
            ">>> "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3itRpgXPHHEo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}